{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d60b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a886edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(\"train.csv\", index_col='PassengerId')\n",
    "\n",
    "def set_age(name):\n",
    "    if(name.find('Mr.') != -1): #male - married or not\n",
    "        return 30\n",
    "    elif(name.find('Mrs.') != -1): #female - married\n",
    "        return 45\n",
    "    elif(name.find('Ms.') != -1): #female - married or not \n",
    "        return 30\n",
    "    elif(name.find('Miss.') != -1): #female - not married \n",
    "        return 20\n",
    "    else:\n",
    "        return 45\n",
    "\n",
    "def clean_dataset(dataset):\n",
    "    popular_port = dataset['Embarked'].dropna().mode()[0] \n",
    "    print(\"This port is most popular and replace all 'NA' to \" + popular_port)\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(popular_port) \n",
    "    dataset['Companions'] = dataset['SibSp'] + dataset['Parch'] #number of people travelling with\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int) #Map sex to 0-1\\n\",\n",
    "    embarked_one_hot = pd.get_dummies(dataset['Embarked'], prefix='Embarked') #Embarks as one-hot\n",
    "    dataset = dataset.join(embarked_one_hot) \n",
    "    dataset['Age'] = dataset.apply(\n",
    "                            lambda row: set_age(row['Name']) if np.isnan(row['Age']) else row['Age'], axis=1)\n",
    "    \n",
    "    dataset = dataset.drop(['Cabin', 'Ticket', 'Name', 'SibSp', 'Parch', 'Embarked'], axis=1) #drop useless columns\n",
    "    return(dataset)\n",
    "    \n",
    "\n",
    "train_data = clean_dataset(input_data)\n",
    "train_data.to_csv('train_data_results.csv', index=False)\n",
    "print(\"Prepared data:\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29686cca",
   "metadata": {},
   "outputs": [],
   "source": [
    " # X and Y ('survived;) axis\n",
    " X = train_data.drop(['Survived'], axis=1).values.astype(float)\n",
    "\n",
    " Y = train_data['Survived'].values\n",
    "\n",
    " def create_model(optimizer='adam', init='uniform'):\n",
    "     #create model\n",
    "     model = keras.Sequential()\n",
    "     model.add( keras.layers.Dense(16, input_dim=X.shape[1], kernel_initializer=init, activation='relu') )\n",
    "     model.add( keras.layers.Dense(8, kernel_initializer=init, activation='relu') )\n",
    "     model.add( keras.layers.Dense(4, kernel_initializer=init, activation='relu') )\n",
    "     model.add( keras.layers.Dense(1, kernel_initializer=init, activation='sigmoid') )\n",
    "\n",
    "     #compile model\n",
    "     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "     print(\"Model created\")\n",
    "     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f437ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 5\n",
    "init = 'glorot_uniform'\n",
    "optimizer = 'rmsprop'\n",
    "\n",
    "#create classfier\n",
    "model_predictions = KerasClassifier(\n",
    "    model=create_model, optimizer=optimizer, init=init, epochs=epochs,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "model_predictions.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9683a2f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predictions for one person\n",
    "d = {'Pclass': [3], 'Sex': [1], 'Age': [22.0], 'Fare': [5.222], \n",
    "            'Companions': [2], 'Embarked_C': [1], 'Embarked_Q': [0], 'Embarked_S':[0]}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "X_data = df.values.astype(float)\n",
    "\n",
    "prediction = model_predictions.predict(X_data)\n",
    "if(prediction):\n",
    "    print(\"You survived!\")\n",
    "else:\n",
    "    print(\"Better luck next time...\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac406392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions using test dataset from kaggle\n",
    "test_data = pd.read_csv(\"test.csv\", index_col='PassengerId')\n",
    "\n",
    "test_data = clean_dataset(test_data) #prepare data to same format as train data\n",
    "#print(test_data.isnull().sum())  #one row has Fare NAN\n",
    "test_data = test_data.fillna(10.000)\n",
    "#print(test_data)\n",
    "X_test = test_data.values.astype(float)\n",
    "test_predictions = model_predictions.predict(X_test)\n",
    "#print(test_predictions)\n",
    "# create file to see the score on kaggle\n",
    "submission = pd.DataFrame({\n",
    "                'PassengerId': test_data.index,\n",
    "                'Survived': test_predictions,\n",
    "})\n",
    "submission.sort_values('PassengerId', inplace=True)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "#prepare same dataframe as test for charts purposes\n",
    "test_data['Survived'] = test_predictions\n",
    "\n",
    "test_data.to_csv('test_data_results.csv', index = False)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48bc15f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
