{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d60b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a886edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(\"train.csv\", index_col='PassengerId')\n",
    "\n",
    "def set_age(name):\n",
    "    if(name.find('Mr.') != -1): #male - married or not\n",
    "        return 30\n",
    "    elif(name.find('Mrs.') != -1): #female - married\n",
    "        return 45\n",
    "    elif(name.find('Ms.') != -1): #female - married or not \n",
    "        return 30\n",
    "    elif(name.find('Miss.') != -1): #female - not married \n",
    "        return 20\n",
    "    else:\n",
    "        return 45\n",
    "    \n",
    "max_fare = input_data['Fare'].max()\n",
    "min_fare = input_data['Fare'].min()\n",
    "print(max_fare, min_fare)\n",
    "\n",
    "def clean_dataset(dataset):\n",
    "    popular_port = dataset['Embarked'].dropna().mode()[0] \n",
    "    print(\"This port is most popular and replace all 'NA' to \" + popular_port)\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(popular_port) \n",
    "    dataset['Companions'] = dataset['SibSp'] + dataset['Parch'] #number of people travelling with\n",
    "    dataset['Female'] = dataset['Sex'].map({'female': 1, 'male': 0})\n",
    "    dataset['Male'] = dataset['Sex'].map({'female': 0, 'male': 1})\n",
    "    #Embarks as one-hot\n",
    "    embarked_one_hot = pd.get_dummies(dataset['Embarked'], prefix='Embarked') \n",
    "    dataset = dataset.join(embarked_one_hot) \n",
    "    #Fare intervals -> one-hot\n",
    "    fares_intervals = pd.cut(x=dataset['Fare'], bins=[0, 50, 100, 200, 500, 1000])\n",
    "    fares_one_hot = pd.get_dummies(fares_intervals, prefix='Fare')\n",
    "    dataset = dataset.join(fares_one_hot)\n",
    "    dataset['Age'] = dataset.apply(\n",
    "                            lambda row: set_age(row['Name']) if np.isnan(row['Age']) else row['Age'], axis=1)\n",
    "    \n",
    "    dataset = dataset.drop(['Cabin', 'Ticket', 'Name', 'SibSp', 'Parch', 'Embarked', 'Sex', 'Fare'], axis=1) #drop useless columns\n",
    "    return(dataset)\n",
    "    \n",
    "    \n",
    "train_data = clean_dataset(input_data)\n",
    "print(\"Prepared data:\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29686cca",
   "metadata": {},
   "outputs": [],
   "source": [
    " # X and Y ('survived;) axis\n",
    " X = train_data.drop(['Survived'], axis=1).values.astype(float)\n",
    "\n",
    " Y = train_data['Survived'].values\n",
    "\n",
    " def create_model(optimizer='adam', init='uniform'):\n",
    "    #create model\n",
    "    model = keras.Sequential()\n",
    "    model.add( keras.layers.Dense(16, input_dim=X.shape[1], kernel_initializer=init, activation='relu') )\n",
    "    model.add( keras.layers.Dense(8, kernel_initializer=init, activation='relu') ) \n",
    "    model.add( keras.layers.Dense(4, kernel_initializer=init, activation='relu') ) \n",
    "    model.add( keras.layers.Dense(1, kernel_initializer=init, activation='sigmoid') )\n",
    "    #compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(\"Model created\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f437ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 5\n",
    "init = 'glorot_uniform'\n",
    "optimizer = 'rmsprop'\n",
    "\n",
    "#create classfier\n",
    "model_predictions = KerasClassifier(\n",
    "    model=create_model, optimizer=optimizer, init=init, epochs=epochs,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "model_predictions.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9683a2f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predictions for one person\n",
    "d = {\n",
    "     'Pclass': [1],    # Ticket class -> 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "     'Name': 'Leo',    # Doesn't matter \n",
    "     'Sex': 'male',    # male / female\n",
    "     'Age': [20],      # in years \n",
    "     'SibSp': [1],     # Number of siblings / spouses aboard the Titanic\n",
    "     'Parch': [0],     # Number of parents / children aboard the Titanic\n",
    "     'Ticket':[0],     # Doesn't matter  \n",
    "     'Fare': [57],     # 0 - 1000\n",
    "     'Cabin': [0],     # Doesn't matter \n",
    "     'Embarked':'Q',   # Port of Embarkation -> C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "    }\n",
    "# add columns that will be missing\n",
    "if(d['Embarked'] == 'C'):\n",
    "    d['Embarked_Q'] = [0]\n",
    "    d['Embarked_S'] = [0]\n",
    "if(d['Embarked'] == 'Q'):\n",
    "    d['Embarked_C'] = [0]\n",
    "    d['Embarked_S'] = [0]\n",
    "if(d['Embarked'] == 'S'):\n",
    "    d['Embarked_Q'] = [0]\n",
    "    d['Embarked_C'] = [0]\n",
    "\n",
    "df = pd.DataFrame(data=d)\n",
    "df = clean_dataset(df) # prepare data\n",
    "\n",
    "X_data = df.values.astype(float)\n",
    "\n",
    "prediction = model_predictions.predict(X_data)\n",
    "if(prediction):\n",
    "    print(\"You survived!\")\n",
    "else:\n",
    "    print(\"Better luck next time...\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac406392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions using test dataset from kaggle\n",
    "test_data = pd.read_csv(\"test.csv\", index_col='PassengerId')\n",
    "\n",
    "max_faret = test_data['Fare'].max()\n",
    "min_faret = test_data['Fare'].min()\n",
    "print(max_faret, min_faret)\n",
    "\n",
    "test_data = clean_dataset(test_data) #prepare data to same format as train data\n",
    "print(test_data.isnull().sum())  #one row has Fare NAN\n",
    "test_data = test_data.fillna(10.000)\n",
    "#print(test_data)\n",
    "X_test = test_data.values.astype(float)\n",
    "test_predictions = model_predictions.predict(X_test)\n",
    "#print(test_predictions)\n",
    "# create file to see the score on kaggle\n",
    "submission = pd.DataFrame({\n",
    "                'PassengerId': test_data.index,\n",
    "                'Survived': test_predictions,\n",
    "})\n",
    "submission.sort_values('PassengerId', inplace=True)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "#prepare same dataframe as test for charts purposes\n",
    "test_data['Survived'] = test_predictions\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5616cafd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
