{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d60b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a886edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(\"train.csv\", index_col='PassengerId')\n",
    "\n",
    "def set_age(name):\n",
    "    if(name.find('Mr.') != -1): #male - married or not\n",
    "        return 30\n",
    "    elif(name.find('Mrs.') != -1): #female - married\n",
    "        return 45\n",
    "    elif(name.find('Ms.') != -1): #female - married or not \n",
    "        return 30\n",
    "    elif(name.find('Miss.') != -1): #female - not married \n",
    "        return 20\n",
    "    else:\n",
    "        return 45\n",
    "    \n",
    "max_fare = input_data['Fare'].max()\n",
    "min_fare = input_data['Fare'].min()\n",
    "print(max_fare, min_fare)\n",
    "\n",
    "def clean_dataset(dataset):\n",
    "    popular_port = dataset['Embarked'].dropna().mode()[0] \n",
    "    print(\"This port is most popular and replace all 'NA' to \" + popular_port)\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(popular_port) \n",
    "    dataset['Companions'] = dataset['SibSp'] + dataset['Parch'] #number of people travelling with\n",
    "    dataset['Female'] = dataset['Sex'].map({'female': 1, 'male': 0})\n",
    "    dataset['Male'] = dataset['Sex'].map({'female': 0, 'male': 1})\n",
    "    #Embarks as one-hot\n",
    "    embarked_one_hot = pd.get_dummies(dataset['Embarked'], prefix='Embarked') \n",
    "    dataset = dataset.join(embarked_one_hot) \n",
    "    #Fare intervals -> one-hot\n",
    "    fares_intervals = pd.cut(x=dataset['Fare'], bins=[0, 50, 100, 200, 500, 1000])\n",
    "    fares_one_hot = pd.get_dummies(fares_intervals, prefix='Fare')\n",
    "    dataset = dataset.join(fares_one_hot)\n",
    "    dataset['Age'] = dataset.apply(\n",
    "                            lambda row: set_age(row['Name']) if np.isnan(row['Age']) else row['Age'], axis=1)\n",
    "    \n",
    "    dataset = dataset.drop(['Cabin', 'Ticket', 'Name', 'SibSp', 'Parch', 'Embarked', 'Sex', 'Fare'], axis=1) #drop useless columns\n",
    "    return(dataset)\n",
    "    \n",
    "\n",
    "train_data = clean_dataset(input_data)\n",
    "train_data.to_csv('train_data_results.csv', index=False)\n",
    "print(\"Prepared data:\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29686cca",
   "metadata": {},
   "outputs": [],
   "source": [
    " # X and Y ('survived;) axis\n",
    " X = train_data.drop(['Survived'], axis=1).values.astype(float)\n",
    "\n",
    " Y = train_data['Survived'].values\n",
    "\n",
    " def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
    "    #create model\n",
    "    model = keras.Sequential()\n",
    "    model.add( keras.layers.Dense(16, input_dim=X.shape[1], kernel_initializer=init, activation='relu') )\n",
    "    model.add( keras.layers.Dense(8, kernel_initializer=init, activation='relu') ) \n",
    "    model.add( keras.layers.Dense(4, kernel_initializer=init, activation='relu') ) \n",
    "    model.add( keras.layers.Dense(1, kernel_initializer=init, activation='sigmoid') )\n",
    "    #compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    print(\"Model created\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f437ce31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Model created\n",
      "Best: 0.824926 using {'batch_size': 10, 'epochs': 200, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.802548 (0.039565) with: {'batch_size': 5, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.811512 (0.034093) with: {'batch_size': 5, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.722717 (0.088535) with: {'batch_size': 5, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.769876 (0.076152) with: {'batch_size': 5, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.738403 (0.099628) with: {'batch_size': 5, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.737512 (0.099671) with: {'batch_size': 5, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.815950 (0.019456) with: {'batch_size': 5, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.801400 (0.029836) with: {'batch_size': 5, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.777961 (0.082209) with: {'batch_size': 5, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.803647 (0.027479) with: {'batch_size': 5, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.815925 (0.017667) with: {'batch_size': 5, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.804727 (0.024607) with: {'batch_size': 5, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.813747 (0.028725) with: {'batch_size': 5, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.777748 (0.082683) with: {'batch_size': 5, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.810326 (0.005477) with: {'batch_size': 5, 'epochs': 150, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.722704 (0.087840) with: {'batch_size': 5, 'epochs': 150, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.736388 (0.101035) with: {'batch_size': 5, 'epochs': 150, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.771006 (0.077402) with: {'batch_size': 5, 'epochs': 150, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.811493 (0.024079) with: {'batch_size': 5, 'epochs': 200, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.819321 (0.020370) with: {'batch_size': 5, 'epochs': 200, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.769939 (0.082513) with: {'batch_size': 5, 'epochs': 200, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.784489 (0.084776) with: {'batch_size': 5, 'epochs': 200, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.723859 (0.090525) with: {'batch_size': 5, 'epochs': 200, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.808091 (0.010084) with: {'batch_size': 5, 'epochs': 200, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.807011 (0.030266) with: {'batch_size': 10, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.800251 (0.033640) with: {'batch_size': 10, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.796905 (0.022891) with: {'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.754228 (0.076006) with: {'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.773235 (0.078500) with: {'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.773241 (0.078650) with: {'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.796861 (0.027118) with: {'batch_size': 10, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.778922 (0.070416) with: {'batch_size': 10, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.684489 (0.084499) with: {'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.811462 (0.018164) with: {'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.770096 (0.080025) with: {'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.807011 (0.024759) with: {'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.804783 (0.036330) with: {'batch_size': 10, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.805900 (0.032952) with: {'batch_size': 10, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.809271 (0.035399) with: {'batch_size': 10, 'epochs': 150, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.774358 (0.078481) with: {'batch_size': 10, 'epochs': 150, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.758709 (0.078453) with: {'batch_size': 10, 'epochs': 150, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.699310 (0.101791) with: {'batch_size': 10, 'epochs': 150, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.814826 (0.015740) with: {'batch_size': 10, 'epochs': 200, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.824926 (0.015109) with: {'batch_size': 10, 'epochs': 200, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.774415 (0.082048) with: {'batch_size': 10, 'epochs': 200, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.815994 (0.026887) with: {'batch_size': 10, 'epochs': 200, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.763198 (0.080239) with: {'batch_size': 10, 'epochs': 200, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.815956 (0.016956) with: {'batch_size': 10, 'epochs': 200, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.811493 (0.028850) with: {'batch_size': 20, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.769933 (0.057242) with: {'batch_size': 20, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.768972 (0.077662) with: {'batch_size': 20, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.725152 (0.089419) with: {'batch_size': 20, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.805825 (0.009339) with: {'batch_size': 20, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.805844 (0.009623) with: {'batch_size': 20, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.806980 (0.015832) with: {'batch_size': 20, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.814870 (0.028846) with: {'batch_size': 20, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.802498 (0.013920) with: {'batch_size': 20, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.773253 (0.078303) with: {'batch_size': 20, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.803641 (0.031998) with: {'batch_size': 20, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.766556 (0.078292) with: {'batch_size': 20, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.818191 (0.015614) with: {'batch_size': 20, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.812629 (0.032432) with: {'batch_size': 20, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.768790 (0.077739) with: {'batch_size': 20, 'epochs': 150, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.820438 (0.012630) with: {'batch_size': 20, 'epochs': 150, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.800264 (0.018504) with: {'batch_size': 20, 'epochs': 150, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.755345 (0.075875) with: {'batch_size': 20, 'epochs': 150, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.805825 (0.025845) with: {'batch_size': 20, 'epochs': 200, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.803609 (0.025469) with: {'batch_size': 20, 'epochs': 200, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.757586 (0.074189) with: {'batch_size': 20, 'epochs': 200, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.783579 (0.085934) with: {'batch_size': 20, 'epochs': 200, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.685657 (0.086619) with: {'batch_size': 20, 'epochs': 200, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.814814 (0.015493) with: {'batch_size': 20, 'epochs': 200, 'init': 'uniform', 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "#create classfier\n",
    "model = KerasClassifier(\n",
    "    model=create_model, verbose=0, init='glorot_uniform')\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 5\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = [50, 100, 150, 200]\n",
    "batches = [5, 10, 20]\n",
    "\n",
    "param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches, init=init)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9683a2f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predictions for one person\n",
    "d = {\n",
    "     'Pclass': [1],    # Ticket class -> 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "     'Name': 'Leo',    # Doesn't matter \n",
    "     'Sex': 'male',    # male / female\n",
    "     'Age': [20],      # in years \n",
    "     'SibSp': [1],     # Number of siblings / spouses aboard the Titanic\n",
    "     'Parch': [0],     # Number of parents / children aboard the Titanic\n",
    "     'Ticket':[0],     # Doesn't matter  \n",
    "     'Fare': [57],     # 0 - 1000\n",
    "     'Cabin': [0],     # Doesn't matter \n",
    "     'Embarked':'Q',   # Port of Embarkation -> C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "    }\n",
    "# add columns that will be missing\n",
    "if(d['Embarked'] == 'C'):\n",
    "    d['Embarked_Q'] = [0]\n",
    "    d['Embarked_S'] = [0]\n",
    "if(d['Embarked'] == 'Q'):\n",
    "    d['Embarked_C'] = [0]\n",
    "    d['Embarked_S'] = [0]\n",
    "if(d['Embarked'] == 'S'):\n",
    "    d['Embarked_Q'] = [0]\n",
    "    d['Embarked_C'] = [0]\n",
    "\n",
    "df = pd.DataFrame(data=d)\n",
    "df = clean_dataset(df) # prepare data\n",
    "\n",
    "X_data = df.values.astype(float)\n",
    "\n",
    "prediction = model_predictions.predict(X_data)\n",
    "if(prediction):\n",
    "    print(\"You survived!\")\n",
    "else:\n",
    "    print(\"Better luck next time...\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac406392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions using test dataset from kaggle\n",
    "test_data = pd.read_csv(\"test.csv\", index_col='PassengerId')\n",
    "\n",
    "max_faret = test_data['Fare'].max()\n",
    "min_faret = test_data['Fare'].min()\n",
    "print(max_faret, min_faret)\n",
    "\n",
    "test_data = clean_dataset(test_data) #prepare data to same format as train data\n",
    "print(test_data.isnull().sum())  #one row has Fare NAN\n",
    "test_data = test_data.fillna(10.000)\n",
    "#print(test_data)\n",
    "X_test = test_data.values.astype(float)\n",
    "test_predictions = model_predictions.predict(X_test)\n",
    "#print(test_predictions)\n",
    "# create file to see the score on kaggle\n",
    "submission = pd.DataFrame({\n",
    "                'PassengerId': test_data.index,\n",
    "                'Survived': test_predictions,\n",
    "})\n",
    "submission.sort_values('PassengerId', inplace=True)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "#prepare same dataframe as test for charts purposes\n",
    "test_data['Survived'] = test_predictions\n",
    "\n",
    "test_data.to_csv('test_data_results.csv', index = False)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48bc15f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
